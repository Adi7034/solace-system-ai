import { serve } from "https://deno.land/std@0.168.0/http/server.ts";

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type",
};

const SYSTEM_PROMPT = `You are Luna, a warm, compassionate AI companion designed specifically to support women through stress, emotional challenges, and menstrual health concerns.

Your personality:
- Gentle, understanding, and non-judgmental
- You speak in a calm, soothing tone
- You validate feelings before offering solutions
- You're knowledgeable about women's health but always recommend consulting healthcare professionals for medical concerns

Your capabilities:
1. **Stress Support**: Offer breathing exercises, grounding techniques, mindfulness practices, and emotional validation
2. **Period Care**: Provide comfort tips for cramps, bloating, mood changes, and general menstrual wellness advice
3. **Emotional Support**: Listen actively, validate feelings, offer gentle encouragement

Guidelines:
- Always acknowledge the user's feelings first
- Offer practical, actionable advice when appropriate
- For breathing exercises, guide step-by-step (e.g., "Let's try box breathing together: breathe in for 4 seconds...")
- Use warm emoji sparingly to convey care ðŸ’œ
- If someone expresses thoughts of self-harm, gently encourage them to reach out to a crisis helpline or trusted person

Remember: You're here to be a supportive presence, not to replace professional medical or mental health care.`;

serve(async (req) => {
  if (req.method === "OPTIONS") {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const { messages } = await req.json();
    const LOVABLE_API_KEY = Deno.env.get("LOVABLE_API_KEY");
    
    if (!LOVABLE_API_KEY) {
      throw new Error("LOVABLE_API_KEY is not configured");
    }

    const response = await fetch("https://ai.gateway.lovable.dev/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${LOVABLE_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "google/gemini-2.5-flash",
        messages: [
          { role: "system", content: SYSTEM_PROMPT },
          ...messages,
        ],
        stream: true,
      }),
    });

    if (!response.ok) {
      if (response.status === 429) {
        return new Response(
          JSON.stringify({ error: "I'm receiving too many messages right now. Please wait a moment and try again. ðŸ’œ" }),
          { status: 429, headers: { ...corsHeaders, "Content-Type": "application/json" } }
        );
      }
      if (response.status === 402) {
        return new Response(
          JSON.stringify({ error: "Service temporarily unavailable. Please try again later." }),
          { status: 402, headers: { ...corsHeaders, "Content-Type": "application/json" } }
        );
      }
      const errorText = await response.text();
      console.error("AI gateway error:", response.status, errorText);
      return new Response(
        JSON.stringify({ error: "I'm having trouble responding right now. Please try again in a moment." }),
        { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json" } }
      );
    }

    return new Response(response.body, {
      headers: { ...corsHeaders, "Content-Type": "text/event-stream" },
    });
  } catch (error) {
    console.error("Chat error:", error);
    return new Response(
      JSON.stringify({ error: error instanceof Error ? error.message : "Something went wrong" }),
      { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json" } }
    );
  }
});
